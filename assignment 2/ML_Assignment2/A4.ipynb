{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "Import the 20 newsgroups text dataset (fetch_20newsgroups) from sklearn\n",
    "datasets.Read through the fetch_20newsgroups help and come to understand how you can\n",
    "load training and test sets with different categories.Use the subset, shuffle, and random_state parameters to load training and test data into bunch objects called train_20news and test_20news.\n",
    "\n",
    "Q1  What is the role of the categories parameter ?\n",
    "\n",
    "Soln => In order to get faster execution times we tend to pick up partial dataset which can be done very easily using categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "Categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "\n",
    "train_20news = fetch_20newsgroups(subset='train', shuffle = True, random_state = 0)\n",
    "test_20news = fetch_20newsgroups(subset='test', shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If you want to apply machine learning methods on text data, you should convert the text\n",
    "contents into the numerical feature vectors.\n",
    "\n",
    "The sklearn.feature_extraction.text sub-module has provided functions to convert text contents \n",
    "into feature vectors. Explore CountVectorizer and TfidfTransformer as well as TfidfVectorizer classes as well as\n",
    "fit, fit_transform and transform methods to figure out how to convert text contents into\n",
    "feature vectors.\n",
    "\n",
    "Explain briefly how these modules and methods perform the conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer :\n",
    "This gives us the occurances of each word as feature to the every record of data, so every data entry\n",
    "will be displayed in the form of features so that every entry is represented by a vector.\n",
    "<br>tfs are calculated by CountVectorier's fit_transform() </br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hard', 'job', 'tough', 'working']\n",
      "[[1 0 0 1]\n",
      " [0 1 1 0]\n",
      " [1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.feature_extraction.text as fe\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = ['hard working', 'tough job', 'hard job']\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = fe.CountVectorizer()\n",
    "cv_fit = cv.fit_transform(data)\n",
    "\n",
    "print(cv.get_feature_names())\n",
    "print(cv_fit.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfTransformer : Transform a count matrix to a normalized tf or tf-idf representation\n",
    "<br>idfs are calculated by TfidfTransformer's fit()</br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.605348508106\n",
      "  (0, 3)\t0.795960541568\n",
      "  (1, 2)\t0.795960541568\n",
      "  (1, 1)\t0.605348508106\n",
      "  (2, 0)\t0.707106781187\n",
      "  (2, 1)\t0.707106781187\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=0.01,max_df = 2.5, lowercase = False, stop_words = 'english')\n",
    "\n",
    "X = vectorizer.fit_transform(data)\n",
    "transformer = TfidfTransformer()\n",
    "X = transformer.fit_transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizer :\n",
    "As tfâ€“idf is very often used for text features, there is also another class called \n",
    "TfidfVectorizer that combines all the options of CountVectorizer and TfidfTransformer\n",
    "in a single model.\n",
    "<br>tfidfs are calculated by TfidfTransformer's transform()</br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t1.0\n",
      "  (0, 0)\t1.0\n",
      "  (0, 4)\t1.0\n",
      "  (0, 2)\t1.69314718056\n",
      "  (1, 3)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (1, 1)\t1.69314718056\n"
     ]
    }
   ],
   "source": [
    "corpus = [\"This is very strange\",\n",
    "          \"This is very nice\"]\n",
    "vectorizer = TfidfVectorizer(\n",
    "                        use_idf=True, \n",
    "                        norm=None, \n",
    "                        smooth_idf=False, \n",
    "                        sublinear_tf=False, \n",
    "                        binary=False,\n",
    "                        min_df=1, max_df=1.0, max_features=None,\n",
    "                        strip_accents='unicode', # retira os acentos\n",
    "                        ngram_range=(1,1), preprocessor=None,\n",
    "                        stop_words=None,\n",
    "                        tokenizer=None,\n",
    "                        vocabulary=None\n",
    "                        )\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>fit :- Trains the model by passing 2 argumnets, 1 for the data and another for the labels<b>   \n",
    "\n",
    "<b>fit_transform :- Normalizes the data and trains the model as well with the training data<b>     \n",
    "\n",
    "<b>transform :- Normalizes the data<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the training data and the test data into feature vectors and place the results in train_vectors and\n",
    "test_vectors. Hint: for the test_vectors, you should call transform instead of\n",
    "fit_transform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tv = fe.TfidfVectorizer()\n",
    "\n",
    "train_vectors = tv.fit_transform(train_20news.data)\n",
    "train_vectors_target = train_20news.target\n",
    "\n",
    "test_vectors = tv.transform(test_20news.data)\n",
    "test_vectors_target = test_20news.target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 130107)\n"
     ]
    }
   ],
   "source": [
    "#(1, 130107)\n",
    "print(train_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "Similar to section 2.5 in the manuscript, apply a random forest classifier with 50 trees in the\n",
    "forest on the train_vectors and calculate and show Accuracy, Precision, Recall, and F1-score\n",
    "quantities as well as confusion matrix of the model on the test_vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy score :- 0.721720658524\n",
      "Precision score :- 0.73197790843\n",
      "Recall score :- 0.710741558512\n",
      "F1 score :- 0.709360877824\n",
      "Confusion matrix :-\n",
      " [[202   6   2   1   5   0   3   3   0   4   1   1   1   4   6  51   4   4\n",
      "    0  21]\n",
      " [  0 257  31  14  12  34   6   4   2   0   1   4   7   6   5   2   1   1\n",
      "    2   0]\n",
      " [  1  34 293  24  11  12   3   1   1   2   0   1   1   2   2   1   1   1\n",
      "    2   1]\n",
      " [  1  28  47 234  24   8  15   3   0   2   1   2  23   2   2   0   0   0\n",
      "    0   0]\n",
      " [  0  17   9  44 257   4  15   5   1   9   0   1  16   3   2   2   0   0\n",
      "    0   0]\n",
      " [  1  50  58   7   9 254   3   3   0   0   0   2   1   1   4   1   1   0\n",
      "    0   0]\n",
      " [  0   7   4   7   6   1 352   3   0   3   0   0   3   0   1   2   0   0\n",
      "    1   0]\n",
      " [  1   8   7  11   8   7  15 292  14   6   5   0  12   4   3   1   2   0\n",
      "    0   0]\n",
      " [  0   1   1   4   1   3   8  16 349   2   1   1   0   3   0   0   5   1\n",
      "    2   0]\n",
      " [  1  10   1   0   3   1   5   1   4 333  32   0   2   2   0   0   0   1\n",
      "    0   1]\n",
      " [  0   3   0   0   3   1   6   0   0  23 359   0   0   1   1   1   0   0\n",
      "    1   0]\n",
      " [  2   6   4   2   3   1   0   2   0   3   0 355   5   0   3   0   7   0\n",
      "    3   0]\n",
      " [  2  31  25  29  23  14  19  17   7   5   8  20 167   7  13   3   0   0\n",
      "    3   0]\n",
      " [  6  34   9   3  16   9  12  10   2  13   2   1  23 235   5   8   4   0\n",
      "    3   1]\n",
      " [  1  13   2   1   1   4   3   2   3   3   2   2   2  13 336   0   3   1\n",
      "    1   1]\n",
      " [  5   6   4   0   4   2   2   0   2   3   0   0   1   3   2 359   0   0\n",
      "    1   4]\n",
      " [  1   4   2   2   1   1   7   4   3   7   1  11   1   6   0   1 305   3\n",
      "    4   0]\n",
      " [ 21   1   0   1   1   5   2   7   0   5  11   1   1   6   3  18   8 280\n",
      "    4   1]\n",
      " [  3   5   0   2   5   2   5   8   1   5   3   1   2   3  12  12 103   3\n",
      "  135   0]\n",
      " [ 34   4   0   0   0   3   2   4   1   3   3   0   3   3   5  76  19   4\n",
      "    5  82]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# This is easy once we have train_vectors\n",
    "RF = RandomForestClassifier(n_estimators=50)\n",
    "RF.fit(train_vectors, train_vectors_target)\n",
    "\n",
    "y_predicted = RF.predict(test_vectors)\n",
    "\n",
    "print('Acuracy score :- '+ str(accuracy_score(test_vectors_target, y_predicted)))\n",
    "print('Precision score :- '+ str(precision_score(test_vectors_target, y_predicted, average = 'macro')))\n",
    "print('Recall score :- '+ str(recall_score(test_vectors_target, y_predicted, average = 'macro')))\n",
    "print('F1 score :- '+ str(f1_score(test_vectors_target, y_predicted, average = 'macro')))\n",
    "print('Confusion matrix :-\\n '+ str(confusion_matrix(test_vectors_target, y_predicted, labels=None, sample_weight=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The Pipeline class is provided by sklearn to sequentially apply a list of transforms and a\n",
    "final estimator. Using the Pipeline class, apply a random forest classifier with 50 trees in the forest on\n",
    "the training data. Then calculate and show Accuracy, Precision, Recall, and F1-score quantities as well\n",
    "as confusion matrix of the model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score :- 0.789613848202\n",
      "Precision score :- 0.815631680878\n",
      "Recall score :- 0.781619515284\n",
      "F1 score :- 0.782062661741\n",
      "Confusion matrix :-\n",
      " [[196  23  18  82]\n",
      " [  2 367  15   5]\n",
      " [ 13 115 259   9]\n",
      " [  3  21  10 364]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.datasets import samples_generator\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# generate some data to play with\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidfVect', fe.TfidfVectorizer()),\n",
    "    ('RF', RandomForestClassifier()),\n",
    "])\n",
    "y_predicted = pipeline.set_params(RF__n_estimators=50).fit(train_20news.data,train_20news.target).predict(test_20news.data)\n",
    "actual = test_20news.target\n",
    "\n",
    "\n",
    "print('Accuracy score :- '+ str(accuracy_score(actual, y_predicted)))\n",
    "print('Precision score :- '+ str(precision_score(actual, y_predicted, average = 'macro')))\n",
    "print('Recall score :- '+ str(recall_score(actual, y_predicted, average = 'macro')))\n",
    "print('F1 score :- '+ str(f1_score(actual, y_predicted, average = 'macro')))\n",
    "print('Confusion matrix :-\\n '+ str(confusion_matrix(actual, y_predicted, labels=None, sample_weight=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Repeat the 2.4 question using MLP classifier with 3 hidden layers with size 10, 20, and 10,\n",
    "and maximum iteration 10. Hint: use sklearn.neural_network.MLPClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishnu/anaconda3/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/vishnu/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score :- 0.665113182423\n",
      "Precision score :- 0.575671985436\n",
      "Recall score :- 0.668560470232\n",
      "F1 score :- 0.59371603849\n",
      "Confusion matrix :-\n",
      " [[228  28   0  63]\n",
      " [  0 384   0   5]\n",
      " [  0  39   0 357]\n",
      " [  2   9   0 387]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishnu/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidfVect', fe.TfidfVectorizer()),\n",
    "    ('MLP', MLPClassifier()),\n",
    "])\n",
    "y_predicted = pipeline.set_params(MLP__hidden_layer_sizes= (10,20,10), MLP__max_iter=10).fit(train_20news.data,train_20news.target).predict(test_20news.data)\n",
    "actual = test_20news.target\n",
    "\n",
    "\n",
    "print('Accuracy score :- '+ str(accuracy_score(actual, y_predicted)))\n",
    "print('Precision score :- '+ str(precision_score(actual, y_predicted, average = 'macro')))\n",
    "print('Recall score :- '+ str(recall_score(actual, y_predicted, average = 'macro')))\n",
    "print('F1 score :- '+ str(f1_score(actual, y_predicted, average = 'macro')))\n",
    "print('Confusion matrix :-\\n '+ str(confusion_matrix(actual, y_predicted, labels=None, sample_weight=None)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
